{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21666e07-419f-46c8-b306-2eaaaba16f1d",
   "metadata": {},
   "source": [
    "# NLP for text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51488ffd-ed4a-48cf-a1b7-98627364a1f0",
   "metadata": {},
   "source": [
    "**Author**: Jonathan TRICARD\n",
    "\n",
    "**Summary**: using a dataset propose by sklearn, we build a DNN model to predict in which category of topic the text belong. Then, we try to use intelligibility method to explain the choice of the model.\n",
    "\n",
    "**ExplainDL**: create a file for each observation sected the given path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd451696-2696-4257-a350-31ce7f1a6574",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c103464c-89c6-464f-b80a-0b8315e0fe42",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from readml.logger import ROOT_DIR\n",
    "from readml.explainers.dl.explain_dl import ExplainDL\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590eb0ef-4b98-4458-a92e-da3749319833",
   "metadata": {},
   "source": [
    "## Initialize the directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dae5101-c77a-475c-ae25-dc7fa99b579b",
   "metadata": {},
   "source": [
    "We need need to build the path to save the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "438d067e-c6c8-484a-85e9-7a3578ec92b1",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_directories_dl(out_path, dir_to_create):\n",
    "    os.chdir(ROOT_DIR)\n",
    "    new_root = os.getcwd()\n",
    "    new_root = \"/\".join(new_root.split(\"/\")[:-1])\n",
    "    os.chdir(new_root)\n",
    "    start = out_path.index(\"/\") + 1\n",
    "    split = out_path[start:].split(\"/\")\n",
    "    for elt in split:\n",
    "        if not os.path.isdir(elt):\n",
    "            os.makedirs(elt)\n",
    "            os.chdir(elt)\n",
    "        else:\n",
    "            os.chdir(elt)\n",
    "    os.chdir(ROOT_DIR)\n",
    "\n",
    "    for elt in dir_to_create:\n",
    "        if not os.path.isdir(os.path.join(out_path, elt)):\n",
    "            os.makedirs(os.path.join(out_path, elt))\n",
    "            \n",
    "def create_dir_test():\n",
    "    dir_to_create = [\"text\"]\n",
    "    out_path = \"../outputs/notebooks/dl\"\n",
    "    initialize_directories_dl(out_path, dir_to_create)\n",
    "\n",
    "create_dir_test()\n",
    "output_path_text_dir = os.path.join(ROOT_DIR, \"../outputs/notebooks/dl\", \"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c9f82",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a088ddb5-5d0d-4f20-bcb5-5e9d6844472d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def create_text_data():\n",
    "    categories = [\n",
    "        'talk.religion.misc',\n",
    "        'sci.space',\n",
    "    ]\n",
    "    remove = ('headers', 'footers', 'quotes')\n",
    "    data_train = fetch_20newsgroups(subset='train',categories=categories, shuffle=True, random_state=42, remove=remove)\n",
    "    data_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42,remove=remove)\n",
    "    vectorizer = CountVectorizer(max_features = 20000, stop_words='english')\n",
    "    vectorizer.fit(data_train['data'])\n",
    "    X_train = pd.DataFrame(vectorizer.transform(data_train['data']).todense(), columns=vectorizer.get_feature_names())\n",
    "    X_test = pd.DataFrame(vectorizer.transform(data_test['data']).todense(), columns=vectorizer.get_feature_names())\n",
    "    y_train, y_test = data_train['target'], data_test['target']\n",
    "    df_train = pd.concat([X_train, pd.Series(y_train, name=\"target_col\")], axis = 1)\n",
    "    df_test = pd.concat([X_test, pd.Series(y_test, name=\"target_col\")], axis = 1)\n",
    "    return X_train, X_test, y_train, y_test, df_train, df_test, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d62cc665-c7cb-41bf-8d0f-8bc8bc467d6c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, df_train, df_test, vectorizer = create_text_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15360e8",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae8ee45-4c9f-4260-a6cb-b3af613ddc30",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def build_model_dnn_text(shape, n_classes, dropout=0.5):\n",
    "    model = Sequential()\n",
    "    node = 512 # number of nodes\n",
    "    n_layers = 4 # number of  hidden layer\n",
    "    model.add(Dense(node,input_dim=shape,activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    for i in range(0, n_layers):\n",
    "        model.add(Dense(node,input_dim=node,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2180253-a8f1-49c9-b9d0-a065a4edc166",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 12:14:02.323649: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-04-08 12:14:02.324149: W tensorflow/core/platform/profile_utils/cpu_utils.cc:116] Failed to find bogomips or clock in /proc/cpuinfo; cannot determine CPU frequency\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 29ms/step - loss: 0.7056 - accuracy: 0.5673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xffff33ea84a8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model_dnn_text(X_train.shape[1], n_classes = len(set(y_train)))\n",
    "model.fit(X_train, y_train) \n",
    "#lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65860e44",
   "metadata": {},
   "source": [
    "## Make intelligibility with readml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e61ecb6a-d052-4132-b67a-27c56b5ac20e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model = model\n",
    "out_path = output_path_text_dir\n",
    "test_data = df_test\n",
    "target_col = \"target_col\"\n",
    "word2idx = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2fe4b9d-61df-4a2e-bf72-fc56209ce92b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "exp = ExplainDL(\n",
    "        model = model,\n",
    "        out_path = out_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "793818d9-7610-44e4-ae9a-3d9415c6df91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: target_col, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.target_col.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac57f771-e336-4bae-9f11-7037c36e5c86",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,050 --- readml --- INFO --- Computing SHAP individual plots for 1th observation\u001b[0m\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,085 --- readml --- INFO --- Computing SHAP individual plots for 2th observation\u001b[0m\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,118 --- readml --- INFO --- Computing SHAP individual plots for 3th observation\u001b[0m\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,150 --- readml --- INFO --- Computing SHAP individual plots for 4th observation\u001b[0m\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,183 --- readml --- INFO --- Computing SHAP individual plots for 5th observation\u001b[0m\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,218 --- readml --- INFO --- Computing SHAP individual plots for 6th observation\u001b[0m\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,250 --- readml --- INFO --- Computing SHAP individual plots for 7th observation\u001b[0m\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,284 --- readml --- INFO --- Computing SHAP individual plots for 8th observation\u001b[0m\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,319 --- readml --- INFO --- Computing SHAP individual plots for 9th observation\u001b[0m\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,352 --- readml --- INFO --- Computing SHAP individual plots for 10th observation\u001b[0m\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,388 --- readml --- INFO --- Saving SHAP individual plots for 1th observation in /workspaces/readml/readml/../outputs/notebooks/dl/text/\u001b[0m\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,412 --- readml --- INFO --- Saving SHAP individual plots for 2th observation in /workspaces/readml/readml/../outputs/notebooks/dl/text/\u001b[0m\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,433 --- readml --- INFO --- Saving SHAP individual plots for 3th observation in /workspaces/readml/readml/../outputs/notebooks/dl/text/\u001b[0m\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,457 --- readml --- INFO --- Saving SHAP individual plots for 4th observation in /workspaces/readml/readml/../outputs/notebooks/dl/text/\u001b[0m\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,488 --- readml --- INFO --- Saving SHAP individual plots for 5th observation in /workspaces/readml/readml/../outputs/notebooks/dl/text/\u001b[0m\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,511 --- readml --- INFO --- Saving SHAP individual plots for 6th observation in /workspaces/readml/readml/../outputs/notebooks/dl/text/\u001b[0m\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,534 --- readml --- INFO --- Saving SHAP individual plots for 7th observation in /workspaces/readml/readml/../outputs/notebooks/dl/text/\u001b[0m\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,553 --- readml --- INFO --- Saving SHAP individual plots for 8th observation in /workspaces/readml/readml/../outputs/notebooks/dl/text/\u001b[0m\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,574 --- readml --- INFO --- Saving SHAP individual plots for 9th observation in /workspaces/readml/readml/../outputs/notebooks/dl/text/\u001b[0m\n",
      "\u001b[1m \u001b[32m 2022-04-08 12:14:11,595 --- readml --- INFO --- Saving SHAP individual plots for 10th observation in /workspaces/readml/readml/../outputs/notebooks/dl/text/\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "exp.explain_text(\n",
    "    test_data = df_test.head(5),\n",
    "    target_col = target_col,\n",
    "    word2idx = word2idx,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d952e59-7f42-4e7b-93b5-0bd204483038",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5dcb9e-f520-4281-9794-7ad4965f6085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
